{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EAhZzS_22KAv",
    "outputId": "d0768e84-58f9-4d02-901d-db09093f5322"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sWHdz_qy2Od9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GVpbip1B2RQV",
    "outputId": "57dd9dd8-4cf6-47e1-a2b8-c13ea21a5047"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1482535, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_path = '/content/gdrive/My Drive/Colab/'\n",
    "\n",
    "df = pd.read_csv(dir_path+\"processed_1stNov.csv\") #  processed_1stNov.csv   final train\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "id": "dya64h_p2eS4",
    "outputId": "6c833e18-6064-41d8-cfd6-21039d289cd6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-f9258d1b-6e1a-495b-b05b-f87e9cb13ce8\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>shipping</th>\n",
       "      <th>Category</th>\n",
       "      <th>Sub_Category_1</th>\n",
       "      <th>Sub_Category_2</th>\n",
       "      <th>combined</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>mlb</td>\n",
       "      <td>1</td>\n",
       "      <td>Men</td>\n",
       "      <td>Tops</td>\n",
       "      <td>T-shirts</td>\n",
       "      <td>mlb cincinnati red t shirt size xl descript yet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>razer</td>\n",
       "      <td>0</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Computers &amp; Tablets</td>\n",
       "      <td>Components &amp; Parts</td>\n",
       "      <td>razer blackwidow chroma keyboard keyboard grea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>target</td>\n",
       "      <td>1</td>\n",
       "      <td>Women</td>\n",
       "      <td>Tops &amp; Blouses</td>\n",
       "      <td>Blouse</td>\n",
       "      <td>avaviv blous ador top hint lace key hole back ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>missing</td>\n",
       "      <td>1</td>\n",
       "      <td>Home</td>\n",
       "      <td>Home Décor</td>\n",
       "      <td>Home Décor Accents</td>\n",
       "      <td>leather hors statu new tag leather hors retail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>missing</td>\n",
       "      <td>0</td>\n",
       "      <td>Women</td>\n",
       "      <td>Jewelry</td>\n",
       "      <td>Necklaces</td>\n",
       "      <td>24k gold plate rose complet certif authent</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9258d1b-6e1a-495b-b05b-f87e9cb13ce8')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-f9258d1b-6e1a-495b-b05b-f87e9cb13ce8 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-f9258d1b-6e1a-495b-b05b-f87e9cb13ce8');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  item_condition_id brand_name  shipping  \\\n",
       "0           0             0                  3        mlb         1   \n",
       "1           1             1                  3      razer         0   \n",
       "2           2             2                  1     target         1   \n",
       "3           3             3                  1    missing         1   \n",
       "4           4             4                  1    missing         0   \n",
       "\n",
       "      Category       Sub_Category_1      Sub_Category_2  \\\n",
       "0          Men                 Tops            T-shirts   \n",
       "1  Electronics  Computers & Tablets  Components & Parts   \n",
       "2        Women       Tops & Blouses              Blouse   \n",
       "3         Home           Home Décor  Home Décor Accents   \n",
       "4        Women              Jewelry           Necklaces   \n",
       "\n",
       "                                            combined  \n",
       "0    mlb cincinnati red t shirt size xl descript yet  \n",
       "1  razer blackwidow chroma keyboard keyboard grea...  \n",
       "2  avaviv blous ador top hint lace key hole back ...  \n",
       "3  leather hors statu new tag leather hors retail...  \n",
       "4         24k gold plate rose complet certif authent  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['log_price']\n",
    "df.drop('log_price', axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dZbowCCd2h2D",
    "outputId": "cdea8f08-a960-4c91-cb06-3d90d636343a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (1037774, 9)\n",
      "Shape of X_cv: (444761, 9)\n",
      "Shape of Y_train: (1037774,)\n",
      "Shape of Y_cv: (444761,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_cv, y_train, y_cv = train_test_split(df, y, test_size=0.3, random_state=0)\n",
    "\n",
    "del(df)\n",
    "del(y)\n",
    "\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of X_cv:\", X_cv.shape)\n",
    "\n",
    "print(\"Shape of Y_train:\", y_train.shape)\n",
    "print(\"Shape of Y_cv:\", y_cv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4E7wWueV22jv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5nOj0Y0B_KsU"
   },
   "source": [
    " Text Tokenization and Padding to be used for Embedding Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PPAUmzyPdvPL"
   },
   "outputs": [],
   "source": [
    "#finding the appropriate number of words to be used for padding\n",
    "a = []\n",
    "for i in X_train['combined']:\n",
    "  a.append(len(i.split(\" \")))\n",
    "\n",
    "b = []\n",
    "for i in X_train['brand_name']:\n",
    "  b.append(len(i.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "id": "H2uNv9-Od6OF",
    "outputId": "5d8eb346-6cd2-4412-ec20-c086a225a3bf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6.71063e+05, 2.34964e+05, 6.63700e+04, 3.09860e+04, 1.65150e+04,\n",
       "        1.20440e+04, 4.69300e+03, 1.05900e+03, 7.30000e+01, 7.00000e+00]),\n",
       " array([  1. ,  20.3,  39.6,  58.9,  78.2,  97.5, 116.8, 136.1, 155.4,\n",
       "        174.7, 194. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336
    },
    "id": "8Y6YecLOd9d5",
    "outputId": "cd214211-d017-4bd1-ca47-bc09f7f0c063"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([7.68445e+05, 0.00000e+00, 1.94356e+05, 0.00000e+00, 6.94760e+04,\n",
       "        0.00000e+00, 5.40300e+03, 0.00000e+00, 8.60000e+01, 8.00000e+00]),\n",
       " array([1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5, 5. , 5.5, 6. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k_T2ibSrd-_h"
   },
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "pad_length_combined = 50\n",
    "pad_length_brand = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wvpkcg5EW6i8"
   },
   "outputs": [],
   "source": [
    "#tokenization for Essay\n",
    "#https://stackoverflow.com/questions/64158898/what-does-keras-tokenizer-num-words-specify\n",
    "\n",
    "def tokenize_and_pad(train_corpus, test_corpus, maxlen):\n",
    "\n",
    "  tokenizer = Tokenizer(oov_token='#OOV#', num_words=None)  #num_words) #num_words=10000\n",
    "  tokenizer.fit_on_texts(train_corpus)\n",
    "\n",
    "  train_tokenized = tokenizer.texts_to_sequences(train_corpus)\n",
    "  train_padded_essay = pad_sequences(train_tokenized, maxlen=maxlen, padding='pre', truncating='pre')\n",
    "  test_tokenized = tokenizer.texts_to_sequences(test_corpus)\n",
    "  test_padded = pad_sequences(test_tokenized, maxlen=maxlen, padding='pre', truncating='pre', dtype='int32')\n",
    "\n",
    "  return train_padded_essay, test_padded, len(tokenizer.word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rXCBv_18Zy3j"
   },
   "outputs": [],
   "source": [
    "X_train_padded_essay, X_test_padded_essay, num_words_combined = tokenize_and_pad(X_train['combined'], X_cv['combined'], maxlen=pad_length_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y0KJw8BdaC8B"
   },
   "outputs": [],
   "source": [
    "X_train_padded_brand, X_test_padded_brand, num_words_brand = tokenize_and_pad(X_train['brand_name'], X_cv['brand_name'], maxlen=pad_length_brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sNvTjTAh_lNE",
    "outputId": "692462a5-d60b-4e38-e3ca-5d1ec3330e2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245453\n",
      "4776\n",
      "(1037774, 50)\n",
      "(1037774, 4)\n"
     ]
    }
   ],
   "source": [
    "print(num_words_combined)\n",
    "print(num_words_brand)\n",
    "print(X_train_padded_essay.shape)\n",
    "print(X_train_padded_brand.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eQbcRKGTrmAN"
   },
   "source": [
    "Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rbgcU63FrkRH"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train[['item_condition_id', 'shipping']])\n",
    "x_train_num_scaled = scaler.transform(X_train[['item_condition_id', 'shipping']])\n",
    "x_test_num_scaled = scaler.transform(X_cv[['item_condition_id', 'shipping']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jOoHkqDi_OO_",
    "outputId": "359e3025-9621-4903-b50c-9970ec7aa777"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1037774, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_num_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pa1foHQMufMi"
   },
   "source": [
    "Merging Category and Sub catregories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ot1ogm4WAkxM"
   },
   "outputs": [],
   "source": [
    "X_train['Categories'] = X_train['Category'] + \" \" + X_train['Sub_Category_1'] + \" \" + X_train['Sub_Category_2']\n",
    "X_cv['Categories'] = X_cv['Category'] + \" \" + X_cv['Sub_Category_1'] + \" \" + X_cv['Sub_Category_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "id": "if6AWthbxPOo",
    "outputId": "5d192479-9d29-42b4-cb21-569c737ce9e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.27377e+05, 2.03433e+05, 2.13548e+05, 0.00000e+00, 1.95618e+05,\n",
       "        3.72570e+04, 0.00000e+00, 3.38570e+04, 2.63910e+04, 2.93000e+02]),\n",
       " array([ 3. ,  3.7,  4.4,  5.1,  5.8,  6.5,  7.2,  7.9,  8.6,  9.3, 10. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#getting the length of sentences\n",
    "a = []\n",
    "for i in X_train['Categories']:\n",
    "  a.append(len(i.split(\" \")))\n",
    "\n",
    "plt.hist(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3fetwgb0xeKh"
   },
   "source": [
    "We will use 9 as Pad length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xpOtIXJ4xPLK",
    "outputId": "268f4d76-33e7-4601-d957-d58e3f6bad2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1007\n",
      "(1037774, 9)\n"
     ]
    }
   ],
   "source": [
    "pad_length_category = 9\n",
    "\n",
    "X_train_padded_category, X_test_padded_category, num_words_category = tokenize_and_pad(X_train['Categories'], X_cv['Categories'], maxlen=pad_length_category)\n",
    "\n",
    "print(num_words_category)\n",
    "print(X_train_padded_category.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EQO6Idt_eW_m"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "opZmPLfSwpi3"
   },
   "source": [
    "Model -1 : with only Brand, Name & Description fields with Embedding vector of length 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jpRKuZl9wqjO"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LeakyReLU, Dense,Input,Activation,Embedding, Conv1D, Flatten, Concatenate, MaxPool2D,MaxPool1D, LSTM, Dropout, BatchNormalization\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.initializers import RandomUniform, HeNormal\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l1,l2\n",
    "\n",
    "import tensorflow\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau, TensorBoard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sklGutz4wtnW",
    "outputId": "442f1d75-62a7-4c48-e17c-086eb688bb9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding layer: (None, 50, 50)\n",
      "LSTM layer: (None, 50, 50)\n",
      "flatten_0 (None, 2500)\n",
      "Embedding layer: (None, 4, 50)\n",
      "LSTM layer: (None, 4, 50)\n",
      "flatten_b (None, 200)\n"
     ]
    }
   ],
   "source": [
    "#combined\n",
    "embedding_features = 50\n",
    "\n",
    "#reason for adding 2 in num_words: 1 for OOV words, 1 because it takes range so range(6) doesn't include 6.. so we add 1\n",
    "\n",
    "input_combined = Input(shape=(pad_length_combined,))\n",
    "Combined_Embedding_layer=Embedding(num_words_combined+2, embedding_features, input_length=pad_length_combined, name = 'Combined')(input_combined)\n",
    "print('Embedding layer:', Combined_Embedding_layer.shape)\n",
    "lstm_layer = LSTM(50, activation='relu', return_sequences=True, input_shape=(pad_length_combined, embedding_features))(Combined_Embedding_layer)\n",
    "print('LSTM layer:', lstm_layer.shape)\n",
    "flatten_0 = Flatten()(lstm_layer)\n",
    "print(\"flatten_0\", flatten_0.get_shape())\n",
    "\n",
    "#brand\n",
    "input_brand = Input(shape=(pad_length_brand,))\n",
    "Brand_Embedding_layer=Embedding(num_words_brand+2, embedding_features, input_length=pad_length_brand, name = 'Brand')(input_brand)\n",
    "print('Embedding layer:', Brand_Embedding_layer.shape)\n",
    "lstm_layer_b = LSTM(50, activation='relu', return_sequences=True, input_shape=(pad_length_brand, embedding_features))(Brand_Embedding_layer)\n",
    "print('LSTM layer:', lstm_layer_b.shape)\n",
    "flatten_b = Flatten()(lstm_layer_b)\n",
    "print(\"flatten_b\", flatten_b.get_shape())\n",
    "\n",
    "#concatenate\n",
    "merged = Concatenate(axis=-1)([flatten_0, flatten_b])  #, flatten_4, flatten_1, flatten_2, flatten_5, Dense_6])\n",
    "\n",
    "Dense2 = Dense(50,activation='relu')(merged)\n",
    "dropout_1 = Dropout(0.4)(Dense2)\n",
    "Dense3 = Dense(10,activation='relu')(dropout_1)\n",
    "dropout_2 = Dropout(0.2)(Dense3)\n",
    "\n",
    "x = BatchNormalization()(dropout_2)\n",
    "\n",
    "output = Dense(1,activation='relu')(x) #(flatten_0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Puo0Ubsq0OC3",
    "outputId": "b1dd103c-b168-4130-ebf3-253935930b6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)           [(None, 50)]         0           []                               \n",
      "                                                                                                  \n",
      " input_7 (InputLayer)           [(None, 4)]          0           []                               \n",
      "                                                                                                  \n",
      " Combined (Embedding)           (None, 50, 50)       12272750    ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " Brand (Embedding)              (None, 4, 50)        238900      ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_4 (LSTM)                  (None, 50, 50)       20200       ['Combined[0][0]']               \n",
      "                                                                                                  \n",
      " lstm_5 (LSTM)                  (None, 4, 50)        20200       ['Brand[0][0]']                  \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)            (None, 2500)         0           ['lstm_4[0][0]']                 \n",
      "                                                                                                  \n",
      " flatten_5 (Flatten)            (None, 200)          0           ['lstm_5[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 2700)         0           ['flatten_4[0][0]',              \n",
      "                                                                  'flatten_5[0][0]']              \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 50)           135050      ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 50)           0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 10)           510         ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 10)           0           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 10)          40          ['dropout_5[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 1)            11          ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 12,687,661\n",
      "Trainable params: 12,687,641\n",
      "Non-trainable params: 20\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = Model(inputs=input_combined, outputs=flatten_0)\n",
    "y = Model(inputs=input_brand, outputs=flatten_b)\n",
    "\n",
    "model = Model(inputs=[x.input, y.input], outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2AlKUkWO0dsO"
   },
   "outputs": [],
   "source": [
    "x_input = [X_train_padded_essay, X_train_padded_brand]\n",
    "x_validation = [X_test_padded_essay, X_test_padded_brand]\n",
    "\n",
    "#https://towardsdatascience.com/deep-learning-which-loss-and-activation-functions-should-i-use-ac02f1c56aa8\n",
    "#https://stackoverflow.com/questions/43855162/rmse-rmsle-loss-function-in-keras\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) \n",
    "\n",
    "#https://medium.com/analytics-vidhya/a-complete-guide-to-adam-and-rmsprop-optimizer-75f4502d83be\n",
    "#https://towardsdatascience.com/a-look-at-gradient-descent-and-rmsprop-optimizers-f77d483ef08b\n",
    "\n",
    "opt = tensorflow.keras.optimizers.Adam(learning_rate=0.001,decay=1e-8)\n",
    "model.compile(loss=root_mean_squared_error, optimizer=\"rmsprop\", metrics =[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3i_efj8a1Oqv",
    "outputId": "cab524c7-63de-498b-8fa1-942ac05c16f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "10378/10378 [==============================] - 1228s 118ms/step - loss: 0.5288 - accuracy: 0.0000e+00 - val_loss: 0.5024 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/4\n",
      "10378/10378 [==============================] - 1158s 112ms/step - loss: 0.5188 - accuracy: 0.0000e+00 - val_loss: 0.5320 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/4\n",
      "10378/10378 [==============================] - 1142s 110ms/step - loss: 0.5100 - accuracy: 0.0000e+00 - val_loss: 0.5316 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/4\n",
      "10378/10378 [==============================] - 1135s 109ms/step - loss: 0.5028 - accuracy: 0.0000e+00 - val_loss: 0.5133 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f32733a9ac0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_input, y=y_train, epochs=4,batch_size=100,\n",
    " validation_data=(x_validation,y_cv))\n",
    "# callbacks=[checkpoint, learning_rate_reduction, history_own, tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wgVNWd_c555O"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AgC3AQlH551n"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZ_1oquo56nH"
   },
   "source": [
    "Model -2 : Using All features with Embedding vector of length 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Iu3uTNx0jvg"
   },
   "outputs": [],
   "source": [
    "tensorflow.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PX0CBPjp55zj",
    "outputId": "a942c87e-a212-49d7-cfbd-d113eae59f5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding layer: (None, 50, 50)\n",
      "LSTM layer: (None, 50, 50)\n",
      "flatten_0 (None, 2500)\n",
      "Embedding layer: (None, 4, 50)\n",
      "LSTM layer: (None, 4, 50)\n",
      "flatten_b (None, 200)\n",
      "Categories Embedding layer: (None, 9, 50)\n",
      "LSTM layer: (None, 9, 50)\n",
      "flatten_c (None, 450)\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 50)]         0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 4)]          0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 9)]          0           []                               \n",
      "                                                                                                  \n",
      " Combined (Embedding)           (None, 50, 50)       12272750    ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " Brand (Embedding)              (None, 4, 50)        238900      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " Categories (Embedding)         (None, 9, 50)        50450       ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 50, 50)       20200       ['Combined[0][0]']               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 4, 50)        20200       ['Brand[0][0]']                  \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  (None, 9, 50)        20200       ['Categories[0][0]']             \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2500)         0           ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 200)          0           ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 450)          0           ['lstm_2[0][0]']                 \n",
      "                                                                                                  \n",
      " Dense_Numerical (Dense)        (None, 50)           150         ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 3200)         0           ['flatten[0][0]',                \n",
      "                                                                  'flatten_1[0][0]',              \n",
      "                                                                  'flatten_2[0][0]',              \n",
      "                                                                  'Dense_Numerical[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 3200)        12800       ['concatenate[0][0]']            \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 500)          1600500     ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 500)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 100)          50100       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 100)          0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 100)         400         ['dropout_1[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 10)           1010        ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            11          ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 14,287,671\n",
      "Trainable params: 14,281,071\n",
      "Non-trainable params: 6,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#combined\n",
    "embedding_features = 50\n",
    "\n",
    "#reason for adding 2 in num_words: 1 for OOV words, 1 because it takes range so range(6) doesn't include 6.. so we add 1\n",
    "\n",
    "input_combined = Input(shape=(pad_length_combined,))\n",
    "Combined_Embedding_layer=Embedding(num_words_combined+2, embedding_features, input_length=pad_length_combined, name = 'Combined')(input_combined)\n",
    "print('Embedding layer:', Combined_Embedding_layer.shape)\n",
    "lstm_layer = LSTM(50, activation='relu', return_sequences=True, input_shape=(pad_length_combined, embedding_features))(Combined_Embedding_layer)\n",
    "print('LSTM layer:', lstm_layer.shape)\n",
    "flatten_0 = Flatten()(lstm_layer)\n",
    "print(\"flatten_0\", flatten_0.get_shape())\n",
    "\n",
    "#brand\n",
    "input_brand = Input(shape=(pad_length_brand,))\n",
    "Brand_Embedding_layer=Embedding(num_words_brand+2, embedding_features, input_length=pad_length_brand, name = 'Brand')(input_brand)\n",
    "print('Embedding layer:', Brand_Embedding_layer.shape)\n",
    "lstm_layer_b = LSTM(50, activation='relu', return_sequences=True, input_shape=(pad_length_brand, embedding_features))(Brand_Embedding_layer)\n",
    "print('LSTM layer:', lstm_layer_b.shape)\n",
    "flatten_b = Flatten()(lstm_layer_b)\n",
    "print(\"flatten_b\", flatten_b.get_shape())\n",
    "\n",
    "#categories\n",
    "input_categories = Input(shape=(pad_length_category,))\n",
    "Categories_Embedding_layer=Embedding(num_words_category+2, embedding_features, input_length=pad_length_category, name = 'Categories')(input_categories)\n",
    "print('Categories Embedding layer:', Categories_Embedding_layer.shape)\n",
    "lstm_layer_c = LSTM(50, activation='relu', return_sequences=True, input_shape=(pad_length_category, embedding_features))(Categories_Embedding_layer)\n",
    "print('LSTM layer:', lstm_layer_c.shape)\n",
    "flatten_c = Flatten()(lstm_layer_c)\n",
    "print(\"flatten_c\", flatten_c.get_shape())\n",
    "\n",
    "#numerical features\n",
    "input_numerical = Input(shape=(2,))\n",
    "Dense_6 = Dense(50,activation='relu', name = 'Dense_Numerical')(input_numerical) #try activation relu\n",
    "\n",
    "#concatenate\n",
    "merged = Concatenate(axis=-1)([flatten_0, flatten_b, flatten_c, Dense_6])\n",
    "\n",
    "x = BatchNormalization()(merged)\n",
    "\n",
    "Dense2 = Dense(500, activation='relu')(x) #(merged)\n",
    "dropout_1 = Dropout(0.4)(Dense2)\n",
    "Dense3 = Dense(100,activation='relu')(dropout_1)\n",
    "dropout_2 = Dropout(0.2)(Dense3)\n",
    "x = BatchNormalization()(dropout_2)\n",
    "\n",
    "x = Dense(10,activation='relu')(x) #(flatten_0)\n",
    "output = Dense(1,activation='relu')(x) #(flatten_0)\n",
    "\n",
    "\n",
    "\n",
    "x = Model(inputs=input_combined, outputs=flatten_0)\n",
    "y = Model(inputs=input_brand, outputs=flatten_b)\n",
    "z = Model(inputs=input_categories, outputs=flatten_c)\n",
    "w = Model(inputs=input_numerical, outputs=Dense_6)\n",
    "\n",
    "\n",
    "model = Model(inputs=[x.input, y.input, z.input, w.input], outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B48jcUtA55xJ",
    "outputId": "de733c03-3cf0-4443-fbf5-975243bec2be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8108/8108 [==============================] - ETA: 0s - loss: 0.5198 - root_mean_squared_error: 0.5258\n",
      "Epoch 1: val_loss improved from inf to 0.46610, saving model to /content/gdrive/My Drive/Colab/best_model2.h5\n",
      "8108/8108 [==============================] - 2116s 260ms/step - loss: 0.5198 - root_mean_squared_error: 0.5258 - val_loss: 0.4661 - val_root_mean_squared_error: 0.4682 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "8108/8108 [==============================] - ETA: 0s - loss: 0.4550 - root_mean_squared_error: 0.4572\n",
      "Epoch 2: val_loss improved from 0.46610 to 0.44957, saving model to /content/gdrive/My Drive/Colab/best_model2.h5\n",
      "8108/8108 [==============================] - 2114s 261ms/step - loss: 0.4550 - root_mean_squared_error: 0.4572 - val_loss: 0.4496 - val_root_mean_squared_error: 0.4517 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "8108/8108 [==============================] - ETA: 0s - loss: 0.4235 - root_mean_squared_error: 0.4256\n",
      "Epoch 3: val_loss improved from 0.44957 to 0.44538, saving model to /content/gdrive/My Drive/Colab/best_model2.h5\n",
      "8108/8108 [==============================] - 2080s 256ms/step - loss: 0.4235 - root_mean_squared_error: 0.4256 - val_loss: 0.4454 - val_root_mean_squared_error: 0.4476 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "8108/8108 [==============================] - ETA: 0s - loss: 0.4004 - root_mean_squared_error: 0.4025\n",
      "Epoch 4: val_loss improved from 0.44538 to 0.44535, saving model to /content/gdrive/My Drive/Colab/best_model2.h5\n",
      "8108/8108 [==============================] - 2050s 253ms/step - loss: 0.4004 - root_mean_squared_error: 0.4025 - val_loss: 0.4454 - val_root_mean_squared_error: 0.4477 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "8108/8108 [==============================] - ETA: 0s - loss: 0.3821 - root_mean_squared_error: 0.3842\n",
      "Epoch 5: val_loss did not improve from 0.44535\n",
      "\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "8108/8108 [==============================] - 2035s 251ms/step - loss: 0.3821 - root_mean_squared_error: 0.3842 - val_loss: 0.4479 - val_root_mean_squared_error: 0.4503 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "8108/8108 [==============================] - ETA: 0s - loss: 0.3565 - root_mean_squared_error: 0.3585\n",
      "Epoch 6: val_loss improved from 0.44535 to 0.44364, saving model to /content/gdrive/My Drive/Colab/best_model2.h5\n",
      "8108/8108 [==============================] - 2071s 255ms/step - loss: 0.3565 - root_mean_squared_error: 0.3585 - val_loss: 0.4436 - val_root_mean_squared_error: 0.4460 - lr: 5.0000e-04\n",
      "Epoch 7/10\n",
      "8108/8108 [==============================] - ETA: 0s - loss: 0.3445 - root_mean_squared_error: 0.3466\n",
      "Epoch 7: val_loss did not improve from 0.44364\n",
      "8108/8108 [==============================] - 2056s 254ms/step - loss: 0.3445 - root_mean_squared_error: 0.3466 - val_loss: 0.4447 - val_root_mean_squared_error: 0.4471 - lr: 5.0000e-04\n",
      "Epoch 8/10\n",
      "8108/8108 [==============================] - ETA: 0s - loss: 0.3361 - root_mean_squared_error: 0.3383\n",
      "Epoch 8: val_loss did not improve from 0.44364\n",
      "\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "8108/8108 [==============================] - 2052s 253ms/step - loss: 0.3361 - root_mean_squared_error: 0.3383 - val_loss: 0.4486 - val_root_mean_squared_error: 0.4510 - lr: 5.0000e-04\n",
      "Epoch 9/10\n",
      "8108/8108 [==============================] - ETA: 0s - loss: 0.3228 - root_mean_squared_error: 0.3248\n",
      "Epoch 9: val_loss did not improve from 0.44364\n",
      "8108/8108 [==============================] - 2034s 251ms/step - loss: 0.3228 - root_mean_squared_error: 0.3248 - val_loss: 0.4493 - val_root_mean_squared_error: 0.4518 - lr: 2.5000e-04\n",
      "Epoch 9: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8ad226e910>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x_input = [X_train_padded_essay, X_train_padded_brand, X_train_padded_category, x_train_num_scaled]\n",
    "x_validation = [X_test_padded_essay, X_test_padded_brand, X_test_padded_category, x_test_num_scaled]\n",
    "\n",
    "filepath= dir_path + \"best_model2.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0.001,patience=3, verbose=1)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience=2, verbose=1, factor=0.5, min_lr=0.0001)\n",
    "\n",
    "#https://towardsdatascience.com/deep-learning-which-loss-and-activation-functions-should-i-use-ac02f1c56aa8\n",
    "#https://stackoverflow.com/questions/43855162/rmse-rmsle-loss-function-in-keras\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) \n",
    "\n",
    "#https://medium.com/analytics-vidhya/a-complete-guide-to-adam-and-rmsprop-optimizer-75f4502d83be\n",
    "#https://towardsdatascience.com/a-look-at-gradient-descent-and-rmsprop-optimizers-f77d483ef08b\n",
    "\n",
    "opt = tensorflow.keras.optimizers.Adam(learning_rate=0.001,decay=1e-8)\n",
    "model.compile(loss=root_mean_squared_error, optimizer=opt, metrics = tensorflow.keras.metrics.RootMeanSquaredError())\n",
    "\n",
    "model.fit(x=x_input, y=y_train, epochs=10, batch_size=128, validation_data=(x_validation,y_cv), callbacks=[checkpoint, earlystop, learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySwYbiZEc7a6"
   },
   "source": [
    "Final Validation loss: 0.443"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y7_dPn7ugBBP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gffse2bRRx8Y"
   },
   "source": [
    "Model 3 -- Using all features but filtering Name & Description features with TF-IDF values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PcFmfbsxRxnk"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=1)\n",
    "X = vectorizer.fit_transform(X_train['combined'])\n",
    "idf = vectorizer.idf_\n",
    "idf_dict = dict(zip(vectorizer.get_feature_names_out(), idf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y8G8wLLIL2hG"
   },
   "outputs": [],
   "source": [
    "idf_dict = dict(zip(vectorizer.get_feature_names_out(), idf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "OMcj3r0QRxhW"
   },
   "outputs": [],
   "source": [
    "#print({k: v for k, v in idf_dict.items() if v <= 12})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BXvq71PfRxfF"
   },
   "outputs": [],
   "source": [
    "for i in list(idf_dict.keys()):\n",
    " if idf_dict[i]>12:\n",
    "  idf_dict.pop(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c1BAu-NNRxc5",
    "outputId": "b9857ea2-1918-4005-cc8a-c0aa499d2da5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20269"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idf_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P6ld8B6pRxan"
   },
   "outputs": [],
   "source": [
    "def filter_text(series):\n",
    " \n",
    "  new_essay = []\n",
    " \n",
    "  for text in series:\n",
    "  #print(text)\n",
    "    words = text.split(' ')\n",
    "    for word in words:\n",
    "      if idf_dict.get(word,-1)!=-1:\n",
    "        words.remove(word)\n",
    "    new_essay.append(' '.join(words))\n",
    "\n",
    "  return new_essay\n",
    "\n",
    "X_train_filtered_combined = filter_text(X_train['combined'])\n",
    "X_test_filtered_combined = filter_text(X_cv['combined'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 352
    },
    "id": "P7oWwOnaRxYh",
    "outputId": "74301d48-0a6f-458d-96e8-963db7b7048e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([7.90794e+05, 1.58982e+05, 4.98700e+04, 2.10510e+04, 1.33530e+04,\n",
       "        3.23000e+03, 4.47000e+02, 3.80000e+01, 7.00000e+00, 2.00000e+00]),\n",
       " array([  1. ,  13.5,  26. ,  38.5,  51. ,  63.5,  76. ,  88.5, 101. ,\n",
       "        113.5, 126. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = []\n",
    "for i in X_train_filtered_combined:\n",
    "  a.append(len(i.split(\" \")))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sTZ0dvE_RxWO"
   },
   "outputs": [],
   "source": [
    "pad_length_combined = 30\n",
    "\n",
    "X_train_padded_essay, X_test_padded_essay, num_words_combined = tokenize_and_pad(X_train['combined'], X_cv['combined'], maxlen=pad_length_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CYdhxfWrgA9L",
    "outputId": "e0575061-f172-41d5-ccfc-1c4c24440a8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding layer: (None, 30, 50)\n",
      "LSTM layer: (None, 30, 50)\n",
      "flatten_0 (None, 1500)\n",
      "Embedding layer: (None, 4, 50)\n",
      "LSTM layer: (None, 4, 50)\n",
      "flatten_b (None, 200)\n",
      "Categories Embedding layer: (None, 9, 50)\n",
      "LSTM layer: (None, 9, 50)\n",
      "flatten_c (None, 450)\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 30)]         0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 4)]          0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 9)]          0           []                               \n",
      "                                                                                                  \n",
      " Combined (Embedding)           (None, 30, 50)       12272750    ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " Brand (Embedding)              (None, 4, 50)        238900      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " Categories (Embedding)         (None, 9, 50)        50450       ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 30, 50)       20200       ['Combined[0][0]']               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 4, 50)        20200       ['Brand[0][0]']                  \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  (None, 9, 50)        20200       ['Categories[0][0]']             \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 1500)         0           ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 200)          0           ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 450)          0           ['lstm_2[0][0]']                 \n",
      "                                                                                                  \n",
      " Dense_Numerical (Dense)        (None, 50)           150         ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 2200)         0           ['flatten[0][0]',                \n",
      "                                                                  'flatten_1[0][0]',              \n",
      "                                                                  'flatten_2[0][0]',              \n",
      "                                                                  'Dense_Numerical[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 2200)        8800        ['concatenate[0][0]']            \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 500)          1100500     ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 500)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 100)          50100       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 100)          0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 100)         400         ['dropout_1[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 10)           1010        ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            11          ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 13,783,671\n",
      "Trainable params: 13,779,071\n",
      "Non-trainable params: 4,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tensorflow.keras.backend.clear_session()\n",
    "\n",
    "#combined\n",
    "embedding_features = 50\n",
    "\n",
    "#reason for adding 2 in num_words: 1 for OOV words, 1 because it takes range so range(6) doesn't include 6.. so we add 1\n",
    "\n",
    "input_combined = Input(shape=(pad_length_combined,))\n",
    "Combined_Embedding_layer=Embedding(num_words_combined+2, embedding_features, input_length=pad_length_combined, name = 'Combined')(input_combined)\n",
    "print('Embedding layer:', Combined_Embedding_layer.shape)\n",
    "lstm_layer = LSTM(50, activation='relu', return_sequences=True, input_shape=(pad_length_combined, embedding_features))(Combined_Embedding_layer)\n",
    "print('LSTM layer:', lstm_layer.shape)\n",
    "flatten_0 = Flatten()(lstm_layer)\n",
    "print(\"flatten_0\", flatten_0.get_shape())\n",
    "\n",
    "#brand\n",
    "input_brand = Input(shape=(pad_length_brand,))\n",
    "Brand_Embedding_layer=Embedding(num_words_brand+2, embedding_features, input_length=pad_length_brand, name = 'Brand')(input_brand)\n",
    "print('Embedding layer:', Brand_Embedding_layer.shape)\n",
    "lstm_layer_b = LSTM(50, activation='relu', return_sequences=True, input_shape=(pad_length_brand, embedding_features))(Brand_Embedding_layer)\n",
    "print('LSTM layer:', lstm_layer_b.shape)\n",
    "flatten_b = Flatten()(lstm_layer_b)\n",
    "print(\"flatten_b\", flatten_b.get_shape())\n",
    "\n",
    "#categories\n",
    "input_categories = Input(shape=(pad_length_category,))\n",
    "Categories_Embedding_layer=Embedding(num_words_category+2, embedding_features, input_length=pad_length_category, name = 'Categories')(input_categories)\n",
    "print('Categories Embedding layer:', Categories_Embedding_layer.shape)\n",
    "lstm_layer_c = LSTM(50, activation='relu', return_sequences=True, input_shape=(pad_length_category, embedding_features))(Categories_Embedding_layer)\n",
    "print('LSTM layer:', lstm_layer_c.shape)\n",
    "flatten_c = Flatten()(lstm_layer_c)\n",
    "print(\"flatten_c\", flatten_c.get_shape())\n",
    "\n",
    "#numerical features\n",
    "input_numerical = Input(shape=(2,))\n",
    "Dense_6 = Dense(50,activation='relu', name = 'Dense_Numerical')(input_numerical) #try activation relu\n",
    "\n",
    "#concatenate\n",
    "merged = Concatenate(axis=-1)([flatten_0, flatten_b, flatten_c, Dense_6])\n",
    "\n",
    "x = BatchNormalization()(merged)\n",
    "\n",
    "Dense2 = Dense(500, activation='relu')(x) #(merged)\n",
    "dropout_1 = Dropout(0.4)(Dense2)\n",
    "Dense3 = Dense(100,activation='relu')(dropout_1)\n",
    "dropout_2 = Dropout(0.2)(Dense3)\n",
    "x = BatchNormalization()(dropout_2)\n",
    "\n",
    "x = Dense(10,activation='relu')(x) #(flatten_0)\n",
    "output = Dense(1,activation='relu')(x) #(flatten_0)\n",
    "\n",
    "\n",
    "\n",
    "x = Model(inputs=input_combined, outputs=flatten_0)\n",
    "y = Model(inputs=input_brand, outputs=flatten_b)\n",
    "z = Model(inputs=input_categories, outputs=flatten_c)\n",
    "w = Model(inputs=input_numerical, outputs=Dense_6)\n",
    "\n",
    "\n",
    "model = Model(inputs=[x.input, y.input, z.input, w.input], outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pSMIwajRULhM",
    "outputId": "c1a79023-49bd-4ee1-b356-6cfa3d3494a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8108/8108 [==============================] - ETA: 0s - loss: 0.5325 - root_mean_squared_error: 0.5516\n",
      "Epoch 1: val_loss improved from inf to 0.47487, saving model to /content/gdrive/My Drive/Mercari/best_model_3_tdidf.h5\n",
      "8108/8108 [==============================] - 1734s 213ms/step - loss: 0.5325 - root_mean_squared_error: 0.5516 - val_loss: 0.4749 - val_root_mean_squared_error: 0.4771 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "8108/8108 [==============================] - ETA: 0s - loss: 0.4649 - root_mean_squared_error: 0.4672\n",
      "Epoch 2: val_loss improved from 0.47487 to 0.45886, saving model to /content/gdrive/My Drive/Mercari/best_model_3_tdidf.h5\n",
      "8108/8108 [==============================] - 1723s 213ms/step - loss: 0.4649 - root_mean_squared_error: 0.4672 - val_loss: 0.4589 - val_root_mean_squared_error: 0.4611 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "8108/8108 [==============================] - ETA: 0s - loss: 0.4359 - root_mean_squared_error: 0.4381\n",
      "Epoch 3: val_loss improved from 0.45886 to 0.45585, saving model to /content/gdrive/My Drive/Mercari/best_model_3_tdidf.h5\n",
      "8108/8108 [==============================] - 1717s 212ms/step - loss: 0.4359 - root_mean_squared_error: 0.4381 - val_loss: 0.4559 - val_root_mean_squared_error: 0.4581 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "8108/8108 [==============================] - ETA: 0s - loss: 0.4128 - root_mean_squared_error: 0.4149\n",
      "Epoch 4: val_loss improved from 0.45585 to 0.45263, saving model to /content/gdrive/My Drive/Mercari/best_model_3_tdidf.h5\n",
      "8108/8108 [==============================] - 1703s 210ms/step - loss: 0.4128 - root_mean_squared_error: 0.4149 - val_loss: 0.4526 - val_root_mean_squared_error: 0.4549 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "8108/8108 [==============================] - ETA: 0s - loss: 0.3945 - root_mean_squared_error: 0.3967\n",
      "Epoch 5: val_loss did not improve from 0.45263\n",
      "8108/8108 [==============================] - 1715s 212ms/step - loss: 0.3945 - root_mean_squared_error: 0.3967 - val_loss: 0.4572 - val_root_mean_squared_error: 0.4595 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "8108/8108 [==============================] - ETA: 0s - loss: 0.3800 - root_mean_squared_error: 0.3821\n",
      "Epoch 6: val_loss did not improve from 0.45263\n",
      "\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "8108/8108 [==============================] - 1757s 217ms/step - loss: 0.3800 - root_mean_squared_error: 0.3821 - val_loss: 0.4579 - val_root_mean_squared_error: 0.4602 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "8108/8108 [==============================] - ETA: 0s - loss: 0.3574 - root_mean_squared_error: 0.3594\n",
      "Epoch 7: val_loss did not improve from 0.45263\n",
      "8108/8108 [==============================] - 1740s 215ms/step - loss: 0.3574 - root_mean_squared_error: 0.3594 - val_loss: 0.4554 - val_root_mean_squared_error: 0.4577 - lr: 5.0000e-04\n",
      "Epoch 7: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe00cc56b20>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_input = [X_train_padded_essay, X_train_padded_brand, X_train_padded_category, x_train_num_scaled]\n",
    "x_validation = [X_test_padded_essay, X_test_padded_brand, X_test_padded_category, x_test_num_scaled]\n",
    "\n",
    "dir_path = '/content/gdrive/My Drive/Mercari/'\n",
    "\n",
    "filepath= dir_path + \"best_model_3_tdidf.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0.0001,patience=3, verbose=1)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience=2, verbose=1, factor=0.5, min_lr=0.0001)\n",
    "\n",
    "#https://towardsdatascience.com/deep-learning-which-loss-and-activation-functions-should-i-use-ac02f1c56aa8\n",
    "#https://stackoverflow.com/questions/43855162/rmse-rmsle-loss-function-in-keras\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) \n",
    "\n",
    "#https://medium.com/analytics-vidhya/a-complete-guide-to-adam-and-rmsprop-optimizer-75f4502d83be\n",
    "#https://towardsdatascience.com/a-look-at-gradient-descent-and-rmsprop-optimizers-f77d483ef08b\n",
    "\n",
    "opt = tensorflow.keras.optimizers.Adam(learning_rate=0.001,decay=1e-8)\n",
    "model.compile(loss=root_mean_squared_error, optimizer=opt, metrics = tensorflow.keras.metrics.RootMeanSquaredError())\n",
    "\n",
    "model.fit(x=x_input, y=y_train, epochs=10, batch_size=128, validation_data=(x_validation,y_cv), callbacks=[checkpoint, earlystop, learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZddYuuHSULb4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dwIkve-9aC5R"
   },
   "source": [
    "Model-4: Trying with Embedding featrues 100 instead of 50 with all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TtJ7tfFmaCPy",
    "outputId": "ff1d985f-6cf9-43df-bae5-ff3c96c000bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding layer: (None, 50, 100)\n",
      "LSTM layer: (None, 50, 50)\n",
      "flatten_0 (None, 2500)\n",
      "Embedding layer: (None, 4, 100)\n",
      "LSTM layer: (None, 4, 50)\n",
      "flatten_b (None, 200)\n",
      "Categories Embedding layer: (None, 9, 100)\n",
      "LSTM layer: (None, 9, 50)\n",
      "flatten_c (None, 450)\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 50)]         0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 4)]          0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 9)]          0           []                               \n",
      "                                                                                                  \n",
      " Combined (Embedding)           (None, 50, 100)      24545500    ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " Brand (Embedding)              (None, 4, 100)       477800      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " Categories (Embedding)         (None, 9, 100)       100900      ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 50, 50)       30200       ['Combined[0][0]']               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 4, 50)        30200       ['Brand[0][0]']                  \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  (None, 9, 50)        30200       ['Categories[0][0]']             \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 2500)         0           ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 200)          0           ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 450)          0           ['lstm_2[0][0]']                 \n",
      "                                                                                                  \n",
      " Dense_Numerical (Dense)        (None, 50)           150         ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 3200)         0           ['flatten[0][0]',                \n",
      "                                                                  'flatten_1[0][0]',              \n",
      "                                                                  'flatten_2[0][0]',              \n",
      "                                                                  'Dense_Numerical[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 3200)        12800       ['concatenate[0][0]']            \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 500)          1600500     ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 500)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 100)          50100       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 100)          0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 100)         400         ['dropout_1[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 10)           1010        ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 1)            11          ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 26,879,771\n",
      "Trainable params: 26,873,171\n",
      "Non-trainable params: 6,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tensorflow.keras.backend.clear_session()\n",
    "\n",
    "#combined\n",
    "embedding_features = 100\n",
    "\n",
    "#reason for adding 2 in num_words: 1 for OOV words, 1 because it takes range so range(6) doesn't include 6.. so we add 1\n",
    "\n",
    "input_combined = Input(shape=(pad_length_combined,))\n",
    "Combined_Embedding_layer=Embedding(num_words_combined+2, embedding_features, input_length=pad_length_combined, name = 'Combined')(input_combined)\n",
    "print('Embedding layer:', Combined_Embedding_layer.shape)\n",
    "lstm_layer = LSTM(50, activation='relu', return_sequences=True, input_shape=(pad_length_combined, embedding_features))(Combined_Embedding_layer)\n",
    "print('LSTM layer:', lstm_layer.shape)\n",
    "flatten_0 = Flatten()(lstm_layer)\n",
    "print(\"flatten_0\", flatten_0.get_shape())\n",
    "\n",
    "#brand\n",
    "input_brand = Input(shape=(pad_length_brand,))\n",
    "Brand_Embedding_layer=Embedding(num_words_brand+2, embedding_features, input_length=pad_length_brand, name = 'Brand')(input_brand)\n",
    "print('Embedding layer:', Brand_Embedding_layer.shape)\n",
    "lstm_layer_b = LSTM(50, activation='relu', return_sequences=True, input_shape=(pad_length_brand, embedding_features))(Brand_Embedding_layer)\n",
    "print('LSTM layer:', lstm_layer_b.shape)\n",
    "flatten_b = Flatten()(lstm_layer_b)\n",
    "print(\"flatten_b\", flatten_b.get_shape())\n",
    "\n",
    "#categories\n",
    "input_categories = Input(shape=(pad_length_category,))\n",
    "Categories_Embedding_layer=Embedding(num_words_category+2, embedding_features, input_length=pad_length_category, name = 'Categories')(input_categories)\n",
    "print('Categories Embedding layer:', Categories_Embedding_layer.shape)\n",
    "lstm_layer_c = LSTM(50, activation='relu', return_sequences=True, input_shape=(pad_length_category, embedding_features))(Categories_Embedding_layer)\n",
    "print('LSTM layer:', lstm_layer_c.shape)\n",
    "flatten_c = Flatten()(lstm_layer_c)\n",
    "print(\"flatten_c\", flatten_c.get_shape())\n",
    "\n",
    "#numerical features\n",
    "input_numerical = Input(shape=(2,))\n",
    "Dense_6 = Dense(50,activation='relu', name = 'Dense_Numerical')(input_numerical) #try activation relu\n",
    "\n",
    "#concatenate\n",
    "merged = Concatenate(axis=-1)([flatten_0, flatten_b, flatten_c, Dense_6])\n",
    "\n",
    "x = BatchNormalization()(merged)\n",
    "\n",
    "Dense2 = Dense(500, activation='relu')(x) #(merged)\n",
    "dropout_1 = Dropout(0.4)(Dense2)\n",
    "Dense3 = Dense(100,activation='relu')(dropout_1)\n",
    "dropout_2 = Dropout(0.2)(Dense3)\n",
    "x = BatchNormalization()(dropout_2)\n",
    "\n",
    "x = Dense(10,activation='relu')(x) #(flatten_0)\n",
    "output = Dense(1,activation='relu')(x) #(flatten_0)\n",
    "\n",
    "\n",
    "\n",
    "x = Model(inputs=input_combined, outputs=flatten_0)\n",
    "y = Model(inputs=input_brand, outputs=flatten_b)\n",
    "z = Model(inputs=input_categories, outputs=flatten_c)\n",
    "w = Model(inputs=input_numerical, outputs=Dense_6)\n",
    "\n",
    "\n",
    "model = Model(inputs=[x.input, y.input, z.input, w.input], outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "PGLHRobeaCIk",
    "outputId": "d22f0c68-cdd6-419a-9117-2dcbd2ebba9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8108/8108 [==============================] - ETA: 0s - loss: 0.5234 - root_mean_squared_error: 0.5354\n",
      "Epoch 1: val_loss improved from inf to 0.46217, saving model to /content/gdrive/My Drive/Mercari/best_model4.h5\n",
      "8108/8108 [==============================] - 3183s 392ms/step - loss: 0.5234 - root_mean_squared_error: 0.5354 - val_loss: 0.4622 - val_root_mean_squared_error: 0.4643 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "8108/8108 [==============================] - ETA: 0s - loss: 0.4528 - root_mean_squared_error: 0.4550\n",
      "Epoch 2: val_loss improved from 0.46217 to 0.44971, saving model to /content/gdrive/My Drive/Mercari/best_model4.h5\n",
      "8108/8108 [==============================] - 3298s 407ms/step - loss: 0.4528 - root_mean_squared_error: 0.4550 - val_loss: 0.4497 - val_root_mean_squared_error: 0.4518 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "8108/8108 [==============================] - ETA: 0s - loss: 0.4206 - root_mean_squared_error: 0.4227\n",
      "Epoch 3: val_loss improved from 0.44971 to 0.44488, saving model to /content/gdrive/My Drive/Mercari/best_model4.h5\n",
      "8108/8108 [==============================] - 3304s 408ms/step - loss: 0.4206 - root_mean_squared_error: 0.4227 - val_loss: 0.4449 - val_root_mean_squared_error: 0.4470 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "8108/8108 [==============================] - ETA: 0s - loss: 0.3966 - root_mean_squared_error: 0.3987\n",
      "Epoch 4: val_loss did not improve from 0.44488\n",
      "8108/8108 [==============================] - 3195s 394ms/step - loss: 0.3966 - root_mean_squared_error: 0.3987 - val_loss: 0.4569 - val_root_mean_squared_error: 0.4592 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "8108/8108 [==============================] - ETA: 0s - loss: 0.3778 - root_mean_squared_error: 0.3799\n",
      "Epoch 5: val_loss did not improve from 0.44488\n",
      "\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "8108/8108 [==============================] - 3163s 390ms/step - loss: 0.3778 - root_mean_squared_error: 0.3799 - val_loss: 0.4450 - val_root_mean_squared_error: 0.4472 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "8108/8108 [==============================] - ETA: 0s - loss: 0.3509 - root_mean_squared_error: 0.3530\n",
      "Epoch 6: val_loss improved from 0.44488 to 0.44174, saving model to /content/gdrive/My Drive/Mercari/best_model4.h5\n",
      "8108/8108 [==============================] - 3161s 390ms/step - loss: 0.3509 - root_mean_squared_error: 0.3530 - val_loss: 0.4417 - val_root_mean_squared_error: 0.4440 - lr: 5.0000e-04\n",
      "Epoch 7/10\n",
      "8108/8108 [==============================] - ETA: 0s - loss: 0.3383 - root_mean_squared_error: 0.3405\n",
      "Epoch 7: val_loss did not improve from 0.44174\n",
      "8108/8108 [==============================] - 3164s 390ms/step - loss: 0.3383 - root_mean_squared_error: 0.3405 - val_loss: 0.4444 - val_root_mean_squared_error: 0.4467 - lr: 5.0000e-04\n",
      "Epoch 8/10\n",
      "8108/8108 [==============================] - ETA: 0s - loss: 0.3291 - root_mean_squared_error: 0.3312\n",
      "Epoch 8: val_loss did not improve from 0.44174\n",
      "\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "8108/8108 [==============================] - 3143s 388ms/step - loss: 0.3291 - root_mean_squared_error: 0.3312 - val_loss: 0.4496 - val_root_mean_squared_error: 0.4519 - lr: 5.0000e-04\n",
      "Epoch 9/10\n",
      "8108/8108 [==============================] - ETA: 0s - loss: 0.3146 - root_mean_squared_error: 0.3167\n",
      "Epoch 9: val_loss did not improve from 0.44174\n",
      "8108/8108 [==============================] - 3123s 385ms/step - loss: 0.3146 - root_mean_squared_error: 0.3167 - val_loss: 0.4497 - val_root_mean_squared_error: 0.4520 - lr: 2.5000e-04\n",
      "Epoch 9: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ffa9c5ae280>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x_input = [X_train_padded_essay, X_train_padded_brand, X_train_padded_category, x_train_num_scaled]\n",
    "x_validation = [X_test_padded_essay, X_test_padded_brand, X_test_padded_category, x_test_num_scaled]\n",
    "\n",
    "dir_path = '/content/gdrive/My Drive/Mercari/'\n",
    "\n",
    "filepath= dir_path + \"best_model4.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "earlystop = EarlyStopping(monitor='val_loss', min_delta=0.001,patience=3, verbose=1)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_loss', patience=2, verbose=1, factor=0.5, min_lr=0.0001)\n",
    "\n",
    "#https://towardsdatascience.com/deep-learning-which-loss-and-activation-functions-should-i-use-ac02f1c56aa8\n",
    "#https://stackoverflow.com/questions/43855162/rmse-rmsle-loss-function-in-keras\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) \n",
    "\n",
    "#https://medium.com/analytics-vidhya/a-complete-guide-to-adam-and-rmsprop-optimizer-75f4502d83be\n",
    "#https://towardsdatascience.com/a-look-at-gradient-descent-and-rmsprop-optimizers-f77d483ef08b\n",
    "\n",
    "opt = tensorflow.keras.optimizers.Adam(learning_rate=0.001,decay=1e-8)\n",
    "model.compile(loss=root_mean_squared_error, optimizer=opt, metrics = tensorflow.keras.metrics.RootMeanSquaredError())\n",
    "\n",
    "model.fit(x=x_input, y=y_train, epochs=10, batch_size=128, validation_data=(x_validation,y_cv), callbacks=[checkpoint, earlystop, learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JP9pSWS84T8p"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mKg2ojDd4T5H",
    "outputId": "e24c28bb-77f2-4e2c-cc1a-5fa6486a99a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------+---------+\n",
      "|                                            Model                                            | CV Loss |\n",
      "+---------------------------------------------------------------------------------------------+---------+\n",
      "|  Model -1 : with only Brand, Name & Description fields with Embedding vector of length 50.  |   0.5   |\n",
      "|              Model -2 : Using All features with Embedding vector of length 50.              |  0.443  |\n",
      "| Model -3 : Using all features but filtering Name & Description features with TF-IDF values. |  0.452  |\n",
      "|         Model-4: Trying with Embedding featrues 100 instead of 50 with all features.        |  0.441  |\n",
      "+---------------------------------------------------------------------------------------------+---------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "table = PrettyTable()\n",
    "table.field_names = [\"Model\", \"CV Loss\"]\n",
    "\n",
    "table.add_row(['Model -1 : with only Brand, Name & Description fields with Embedding vector of length 50.','0.5'])\n",
    "table.add_row(['Model -2 : Using All features with Embedding vector of length 50.','0.443'])\n",
    "table.add_row(['Model -3 : Using all features but filtering Name & Description features with TF-IDF values.','0.452'])\n",
    "table.add_row(['Model-4: Trying with Embedding featrues 100 instead of 50 with all features.','0.441'])\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_YZb4AG25Uqu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
